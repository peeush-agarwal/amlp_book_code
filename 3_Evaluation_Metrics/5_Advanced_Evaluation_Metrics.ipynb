{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Evaluation metrics\n",
    "\n",
    "1. Cohen's Kappa\n",
    "2. Matthew's Correlation Coefficient (MCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohen's Kappa\n",
    "\n",
    "Also known as **Quadratic Weighted Kappa (QWK)**. It is basically the agreement between the ratings. The ratings can be in range 0 to N and the predictions are also in same range. An agreement can be defined as how close these ratings are to each other. If agreement is high, then score is closer towards 1.0. In case of lower agreement, score is closer to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333337"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "\n",
    "y_true = [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
    "y_pred = [2, 1, 3, 1, 2, 3, 3, 1, 2]\n",
    "\n",
    "cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A QWK greater than 0.85 is considered to be very good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matthew's Correlation coefficient\n",
    "\n",
    "It ranges from -1 to 1.\n",
    "+ 1 is perfect prediction\n",
    "+ -1 is imperfect prediction\n",
    "+ 0 is random prediction\n",
    "\n",
    "$ MCC = \\dfrac{TP*TN - FP*FN}{\\sqrt{(TP+FP)*(FN+TN)*(FP+TN)*(TP+FN)}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_metrics import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the MCC score\n",
    "    \n",
    "    :param y_true: Actual values\n",
    "    :param y_pred: Predicted values\n",
    "    :returns MCC score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    \n",
    "    num = tp * tn - fp * fn\n",
    "    den = np.sqrt((tp+fp)*(fn+tn)*(tp+fn)*(fp+tn))\n",
    "    return num/den"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
